<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="论文," />










<meta name="description" content="用于图像去噪的双CNN神经网络的设计与训练摘要​    用于图像去噪的深卷积神经网络(CNNs)近年来引起了越来越多的研究兴趣。然而，普通网络不能恢复复杂任务的精细细节，例如真实的噪声图像。在本文中，我们提出了一种双重去噪网络(DudeNet)来恢复干净的图像。具体地，DudeNet由四个模块组成：特征提取块、增强块、压缩块和重构块。特征提取模块采用稀疏机制，通过两个子网络分别提取全局特征和局部特">
<meta property="og:type" content="article">
<meta property="og:title" content="用于图像去噪的双CNN神经网络的设计与训练">
<meta property="og:url" content="http://yoursite.com/2020/07/10/%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%8E%BB%E5%99%AA%E7%9A%84%E5%8F%8CCNN%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%AE%AD%E7%BB%83/index.html">
<meta property="og:site_name" content="GeekOUC">
<meta property="og:description" content="用于图像去噪的双CNN神经网络的设计与训练摘要​    用于图像去噪的深卷积神经网络(CNNs)近年来引起了越来越多的研究兴趣。然而，普通网络不能恢复复杂任务的精细细节，例如真实的噪声图像。在本文中，我们提出了一种双重去噪网络(DudeNet)来恢复干净的图像。具体地，DudeNet由四个模块组成：特征提取块、增强块、压缩块和重构块。特征提取模块采用稀疏机制，通过两个子网络分别提取全局特征和局部特">
<meta property="article:published_time" content="2020-07-10T05:51:07.193Z">
<meta property="article:modified_time" content="2020-07-10T05:55:08.663Z">
<meta property="article:author" content="田济荣">
<meta property="article:tag" content="论文">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2020/07/10/用于图像去噪的双CNN神经网络的设计与训练/"/>





  <title>用于图像去噪的双CNN神经网络的设计与训练 | GeekOUC</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?345da8a17ad1f3825bc080f35df3590b";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




<meta name="generator" content="Hexo 4.2.1"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">GeekOUC</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Hello,world.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-简历">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            简历
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-schedule">
          <a href="/schedule/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-calendar"></i> <br />
            
            日程表
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/10/%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%8E%BB%E5%99%AA%E7%9A%84%E5%8F%8CCNN%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%AE%AD%E7%BB%83/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="田济荣">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GeekOUC">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">用于图像去噪的双CNN神经网络的设计与训练</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-07-10T13:51:07+08:00">
                2020-07-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87/" itemprop="url" rel="index">
                    <span itemprop="name">论文</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="用于图像去噪的双CNN神经网络的设计与训练"><a href="#用于图像去噪的双CNN神经网络的设计与训练" class="headerlink" title="用于图像去噪的双CNN神经网络的设计与训练"></a>用于图像去噪的双CNN神经网络的设计与训练</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>​    用于图像去噪的深卷积神经网络(CNNs)近年来引起了越来越多的研究兴趣。然而，普通网络不能恢复复杂任务的精细细节，例如真实的噪声图像。在本文中，我们提出了一种双重去噪网络(DudeNet)来恢复干净的图像。具体地，DudeNet由四个模块组成：特征提取块、增强块、压缩块和重构块。特征提取模块采用稀疏机制，通过两个子网络分别提取全局特征和局部特征。增强块收集并融合全局和局部特征，为后一种网络提供补充信息。压缩块细化提取的信息并压缩网络。最后，利用重建块重建去噪后的图像。DudeNet具有以下优点：</p>
<p>(1)具有解析机制的双重网络可以提取互补特征，增强去噪器的泛化能力。</p>
<p>(2)融合全局特征和局部特征可以提取显著特征，恢复复杂噪声图像的精细细节。</p>
<p>(3)采用小尺寸滤波器来降低去噪器的复杂度。大量的实验证明了DudeNet比现有最先进的去噪方法的优越性。</p>
<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>​    图像去噪是低级计算机视觉领域的一个长期存在的问题[1，2]。一般而言，它可用于通过退化模型y=x+v恢复高质量图像(也被视为潜在的干净图像)x，其中y表示受污染(有噪声)图像，v是标准差为σ的加性高斯白噪声。在贝叶斯推理观点中，先验知识对图像去噪有重要影响[3]。例如，加权核范数最小化(WNNM)[4]利用奇异值来导出不同的权重作为解。然后，小波NNM处理基于非局部自相似性的图像去噪。块匹配和3-D滤波(BM3D)方法[5]结合了3D数据和稀疏性，优先处理图像去噪问题。同时使用信号处理技术和现有技术有利于图像处理应用[6]。为了提高去噪的效率，开发了字典学习技术来抑制噪声[7]。</p>
<p>​    虽然基于先验的方法可以获得很好的去噪效果，但它们面临着参数手动设置和复杂的优化算法的挑战。针对这些问题，提出了多种判别学习方法来训练图像先验模型。例如，施密特等人提出了收缩场级联(CSF)模型[8]，利用展开的半二次优化算法进行图像恢复。Chen等人设计了可训练非线性反应扩散(TNRD)方法[9]来训练基于梯度下降推理的专家领域图像先验的去噪模型。虽然这些方法对图像去噪效果较好，但它们的应用受到所用先验的限制。此外，它们需要几个手动调整的参数才能获得最佳参数[10]。另外，上述方法只适用于一定的噪声水平，对盲去噪效果不佳。</p>
<p>![img](Users/tianjirong/Library/Group Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image001.png)</p>
<p>​    最近提出的CNN在很大程度上改进了图像去噪[11]。张等人提出了去噪卷积神经网络(DnCNN)[10]，它使用残差学习(RL)和批处理重整化(BN)[12]来去除噪声。具体地说，DnCNN首先应用单个模型来处理多个应用，例如，图像去噪、超分辨率和去块。这些多用途方法的有效性取决于所使用的核心结构。如果它们的核心结构不能很好地恢复动态或复杂任务的清晰图像细节，例如真实世界中损坏的图像和盲噪声，这些方法可能不能很好地执行[13]。为了解决这些问题，我们提出了一种计算量较小的双重去噪网络(DudeNet)，如图1所示。DudeNet由四个部分组成：特征提取块(FEB)、增强块(EB)、压缩块(CB)和重构块(RB)。具体地说，具有稀疏机制的FEB首先从给定的噪声图像中提取全局和区域特征。然后，为了逐步增强残差信息，EB通过两阶段机制融合全局特征和局部特征，为后一网络提供补充信息。然后，对CB进行叠加，提取得到的残差图像，减少局部参数的个数。最后，RB从残差和噪声图像中重建出潜在的干净图像。</p>
<p><strong>拟议的DudeNet有几个优点：</strong></p>
<p>(1)采用稀疏机制的双网络可以提取不同的特征，提高去噪器处理复杂任务(如真实世界中的图像和盲噪声)的泛化能力。提出的双网络具有稀疏机制，可以提取不同的特征，提高去噪器处理复杂任务的能力。</p>
<p>(2)融合全局特征和局部特征可以获得显著的特征来恢复细节，可以合并双网络来处理复杂的去噪任务。</p>
<p>(3)采用小尺寸滤波器来降低去噪器的复杂度。</p>
<p>本文的其余部分组织如下:第二节综述了与我们提出的方法相关的几项工作。第三节详细阐述了拟议的DudeNet。第四节给出了所提出的DudeNet的综合实验结果，并进行了深入的分析。第五节得出结论。</p>
<h3 id="2-相关工作："><a href="#2-相关工作：" class="headerlink" title="2 相关工作："></a>2 相关工作：</h3><p><strong>A.  深度CNN在图像去噪中的应用：</strong></p>
<p>由于深层CNN的表达能力强、速度快，许多基于CNN的去噪方法已经成为低层视觉任务的热门方法[14]。张某等人提出了一种快速灵活的去噪网络以及基于噪声级图和含噪图像的FFDNet盲去噪方法[15]。为了更好地权衡效率和专门任务之间的关系，张等人提出了一种新的解决方案。提出了一种判别学习和基于模型优化相结合的图像复原CNN(IRCNN)[16]方法来预测干净的图像。为了便于培训，刘等人提出了一种深度多层小波CNN(MWCNN)[17]，它融合了Unet结构[18]和小波来提取频率特征，用于图像恢复任务。Tai等人的研究成果提出了一种由递归和门单元组成的深层次持久存储网络(又称MemNet)[19]来恢复高质量的图像，以挖掘更准确的信息。毛等人开发了一种更深的30层残差编解码器网络(RED30)[20]，由大量卷积和随后的转置卷积组成，以获得更清晰的图像。虽然有些方法在图像恢复方面取得了很好的效果，但它们都依赖于主体结构。当主要结构的细节恢复良好时，其性能是完美的。然而，对于多变或复杂的任务，如盲噪声和真实噪声图像，主要结构不能很好地恢复，这些方法效果不佳[13]。为了解决这个问题，潘等人[13]提出用双卷积神经网络提取互补特征来增强低水平视觉任务中恢复的细节。受此启发，我们使用双CNN来去除噪声，特别是变化的噪声图像(即现实应用中的受损图像和盲噪声)。</p>
<p><strong>B.  用于图像去噪的基于深度CNN的模块：</strong></p>
<p>由于端到端的连接架构，具有灵活插件的CNN被广泛用于许多任务，即图像[21]、视频[22]和文本应用[23]。具体地说，CNN中的模块或块用于低级计算机视觉，特别是图像超分辨率[24，25]和去噪[26]。基于模块的深度神经网络主要分为两类：提高性能、加快速度。对于第一个方面，学者们主要是融合获得的多个特征来增强CNN的表达能力。例如，深度提升框架(DBF)[27]使用特征提取、特征集成和重构块来抑制噪声。具体地说，特征集成块使用多个级联操作来融合特征。级联残差网络(CARN)[28]通过重复级联残差块实现图像超分辨率的集成特征。残差密集网络(RDN)[29]通过递归使用残差块来重复融合全局和局部特征，以提高图像的超分辨率性能。</p>
<p>对于第二个方面，压缩网络是提高网络速度的常用方法。例如，一种轻量级特征融合网络(LFFN)[30]被用来减小卷积核大小和压缩训练模型。自适应加权超分辨网络(AWSRN)[31]利用自适应加权多尺度(AWMS)模块对小尺度卷积进行裁剪。信息提取网络(IDN)[32]使用三个块(即，信息提取块、信息提取块、构造块)来提取所获得的特征。具体地说，信息精馏模块使用1×1的分组卷积和卷积核来降低网络参数和计算量。这些方法在图像超分辨率或去噪性能或效率上都取得了较好的效果。因此，本文提出了基于块的DudeNet来缩小去噪效率和去噪性能之间的差异，以达到去噪的目的。DudeNet的详细信息将在第三节中显示。</p>
<h3 id="3-所提方法"><a href="#3-所提方法" class="headerlink" title="3 所提方法:"></a>3 所提方法:</h3><p><strong>A 网络结构：</strong></p>
<p>![img](Users/tianjirong/Library/Group Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image002.png)</p>
<p>​    如图1所示，所提出的DudeNet由四个部分组成：特征提取块(FEB)、增强块(EB)、压缩块(CB)和重构块(RB)。FEB采用稀疏机制，既能提取不同的特征，又能降低网络的深度。EB通过将特征融合在两个子网络中来增强提取的特征，这对于被未知类型的噪声污染的图像特别有用，例如许多真实的被破坏的图像和盲噪声。CB对网络进行压缩，以降低计算成本。最后用RB重建干净的图像。</p>
<p>​    具体地，FEB包含两个子网络，分别是FEB-Net1和FEBnet2，其中FEBnet1包括稀疏机制。我们将DudeNet的输入表示为Y，输出表示为X。利用这两个16层子网络从输入的含噪图像中提取两个不同的特征映射。FEB CAN的过程表示为：</p>
<p>![img](Users/tianjirong/Library/Group Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image003.png)</p>
<p>​    其中，Fi(Y)和FEBi分别表示第i个网络的特征提取函数和提取的特征。</p>
<p>​    EB包含两个部分：增强块1(EB1)和增强块2(EB2)。FEB的输出被送入EB1，EB1通过链式方式融合来自FEB的上述两个子网的两个不同的特征：</p>
<p>![img](Users/tianjirong/Library/Group Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image004.png)</p>
<p>​    其中E表示EB1和EB2的功能，OE1表示EB1的输出。</p>
<p>​    CB由三个压缩块(CB1)、压缩块2(CB2)和压缩块3(CB3)组成。请注意，CB1集成在FEBnet1中。放置在EB1和EB2之间的CB2用于细化提取的特征，如下所述：</p>
<p>![img](Users/tianjirong/Library/Group Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image005.png)</p>
<p>​    其中C1分别表示CB1、CB2和CB3的功能。OCB2是CB2的输出。</p>
<p>在CB2之后，EB2用于获取如下公式的补充信息：</p>
<p>![img](Users/tianjirong/Library/Group Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image006.png)</p>
<p>​    其中OE2代表EB2的输出。</p>
<p>​    然后，CB3进一步对EB2的输出进行如下处理：</p>
<p>![img](Users/tianjirong/Library/Group Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image007.png)</p>
<p>​    其中OCB3表示CB3的输出。</p>
<p>​    最后，利用RB构造潜在的干净版本。使用以下残差运算从所获得的残差特征OCB3中提取输入Y：</p>
<p>![img](Users/tianjirong/Library/Group Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image008.png)</p>
<p>​    其中‘−’表示残差操作。</p>
<p> <strong>B．特征提取块(FEB)：</strong></p>
<p>​    FEB用于提取可靠的视觉特征。FEB由第一网络和第二网络组成。具体地说，第一个网络可以分为三个模块：Conv+BN+RELU、扩展Conv+BN+RELU和Conv。具体地说，在所提出的稀疏机制中，扩张卷积+BN+RELU依次执行扩张卷积[33]、批归一化[12]和校正线性单元[34]。Conv+BN+RELU在第1、3、4、6、7、8、10、11、13、14、15层起作用，扩张型Conv+BN+REU设计在第2、5、9、12层，Conv形成第16层。所有卷积层的滤波器大小均设置为3×3，2-16层的大小为64×3×3×64。第1层的大小为c×3×3×64，其中c是通道号，其中c=1和c=3分别表示输入的噪声图像是灰度图像和彩色图像。此外，层2-12包括FEBnet1中的稀疏机制。文献[35]表明，稀疏性可以放大少量大能点的效应。基于此，我们在FEB1的FEBnet1中提出了一种稀疏机制。具体地说，第2、5、9和12层通过一系列膨胀因子为2的膨胀卷积可以捕捉到丰富的上下文信息，即大能量点。FEBnet1的其他层进行普通卷积提取的特征比膨胀卷积层提取的特征相对较少，即小能量点。大能点和低能点的联合利用利用了稀疏性。因此，FEBnet1中的第2-12层称为稀疏机制。因此，FEBnet1的功能可以表示如下：</p>
<p>![img](Users/tianjirong/Library/Group Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image009.png)</p>
<p>​    其中CBR1、S、CBR3和C分别代表Conv+BN+REU的功能，设计了稀疏机制，设计了3个Conv+BN+REU和1个3×3卷积。这被转换为F1(Y)=feb1通过(1)。</p>
<p>​    第二子网FEBnet2包含两个不同的模块：Conv+RELU和CB1。具体地说，Conv+REU指的是滤波器大小为3×3的卷积，然后是RELU。CB1通过1×1卷积层实现。第2-15层的尺寸均为64×3×3×64。第1层和第16层的尺寸分别设计为c×3×3×64和64×1×1×64，其中c为通道数。FEBnet2的程序可以制定如下：</p>
<p>![img](Users/tianjirong/Library/Group Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image010.png)</p>
<p>​    其中CR15表示十五个Conv+REU的功能。</p>
<p><strong>C.  增强模块(EB)：</strong></p>
<p>​    EB使用两个部分来增强所设计网络的学习功能，适用于实际应用中的未知类型的噪声，如受损图像和盲噪声。拟议的EB在FEB和CB3之间工作，包括EB1和EB2两个部分。具体地说，EB1在FEB和CB2之间起作用。EB1由三部分组成：融合部分、BN部分和RELU部分。首先，融合部分通过串联操作集成来自不同网络(第一和第二网络)的两种不同类型的特征[36]。众所周知，在第一个网络中通过膨胀卷积获得的特征与在第二个网络中通过膨胀卷积获得的特征是不同的，这导致在EB1中获得的特征的分布有很大的不同。因此，使用BN来消除不良影响。最后，利用RELU将得到的线性特征转换为非线性特征。这一过程可以制定如下：</p>
<p>![img](Users/tianjirong/Library/Group Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image011.png)</p>
<p>​    其中B是BN的函数，R表示激活函数RELU。EB2，介于CB2和CB3之间，将DudeNet的输入和CB2的输出连接起来，产生重要信息。这一过程可以用以下表达式表示：</p>
<p>![img](Users/tianjirong/Library/Group Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image012.png)</p>
<p>​    其中OE2扮演CB3的角色。</p>
<p><strong>D.  压缩块(Cb)和重建块(Rb)：</strong></p>
<p>​    利用CB对提取出的特征进行更准确的提取，降低了计算量。它由CB1、CB2和CB3三部分组成。具体地说，尺寸为64×1×1×64的CB1被放置在Feb的FEBnet2的第16层中，尺寸为128×1×1×c的CB2被放置在EB1和EB2之间，尺寸为2c×1×1×c的CB3被放置在EB2和Rb之间，其中c是通道尺寸。此外，CB1、CB2和CB3由1×1卷积实现，这可以降低它们的维数并提高DudeNet的效率，因为已知1×1的卷积可以压缩数据[32]。上面的插图显示了CB1和CB2。因此，CB3着重显示如下。</p>
<p>![img](Users/tianjirong/Library/Group Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image013.png)</p>
<p>​    其中，OCB3表示如图1所示的残差图像(视为噪声映射)。RB使用(6)来构造预测的干净图像。</p>
<p><strong>E．损失函数：</strong></p>
<p>​    我们使用下面的均方误差(MSE)[37]作为目标函数(也称为损失函数)来测量预测残差图像R(Yj)和对应的地面真实图像Yj−Xj之间的差异，其中Xj表示第j个清洁图像：</p>
<p>![img](Users/tianjirong/Library/Group Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image014.png)</p>
<p>​    其中θ表示DudeNet中训练的模型的参数。{(yj，xj)}nj=1表示N个噪声-清洁图像对。损失函数用于通过ADAM优化器[38]恢复潜在清洁图像。</p>
<h3 id="4-实验："><a href="#4-实验：" class="headerlink" title="4 实验："></a>4 实验：</h3><p><strong>A.  训练数据集：</strong></p>
<p>​    我们的训练数据分为两部分：合成图像和真实噪声图像。大小为180×180的合成噪声图像包括灰度图像和彩色图像。为了创建该训练集，我们为合成噪声数据选择了相同的400幅图像[6]。我们使用以下两种方法[39]来增加合成噪声图像的训练数据。(1)采用降尺度因子为0.7、0.8、0.9和1的双三次插值对训练数据集进行扩展。(2)采用以下八种操作来增加训练样本的多样性：无操作(即，原始图像)、90◦逆时针旋转、180◦逆时针旋转、2 70◦逆时针旋转、水平翻转、90◦逆时针旋转然后水平翻转、180◦逆时针旋转然后水平翻转、270◦逆时针旋转然后水平翻转。为了使训练后的模型更稳健，每次操作只能应用于一幅图像，并且每幅图像在一个时期内使用四次。</p>
<p>​    对于真实的噪声图像，我们使用大小为512×512的100个JPEG压缩图像[40]作为训练数据，这些图像是使用五种不同的数字设备收集的：佳能80D、尼康D800、佳能600D、索尼A7 II和佳能5D Mark II，它们带有不同参数的传感器(即800、1,600、3,200、6,400、12,800和25,600)。由于这些真实的噪声图像被压缩，对图像去噪提出了更大的挑战。</p>
<p><strong>B．测试集：</strong></p>
<p>​    所提出的DudeNet在五个公共基准数据集上进行了测试：BSD68[41]、Set12[7]、CBSD68[41]、Kodak24[42]和CC[43]。在这些数据集中，BSD68和Set12分别包含68个和12个不同场景的灰度图像。两个数据集中每个图像的大小分别为321×481和256×256。CBSD68和Kodak24分别包含68色和24色自然图像。CBSD68和Kodak24的图像大小分别为321×481和500×500。CC包含15个损坏的512×512真实世界，部分如图2所示，由3个数字设备捕获：佳能5D Mark III、尼康D600和尼康D800，具有三个ISO值(例如1,600、3,200和6,400)。</p>
<p>![img](Users/tianjirong/Library/Group Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image015.png)</p>
<p><strong>C．实施细节：</strong></p>
<p>​    DudeNet的深度为18。为了加快训练速度，按照文献[44]的建议，将训练样本裁剪成大小为41×41的块来训练去噪模型。在训练阶段，初始参数设置如下：学习率为10−3，ε=10−8，批次大小为。12 8，β1=0.9，β2=0.999[45]。培训的数量：对于真实和合成噪声图像的去噪模型，Epochs为70，其中学习率设置为10−3到10−5。</p>
<p><strong>D.网络分析：</strong></p>
<p>​    1)感受野的设计：与整个图像相比，将图像分成多个块可以降低计算成本[44]。具体地说，补丁的大小通常略大于所设计网络的接收场大小。在DudeNet中，第一和第二网络的感受野大小分别为41×41和32×32，遵循[33]。需要注意的是，补丁的大小应该大于DudeNet的接受场大小，否则，补丁的大小不能满足网络填充的要求，这将降低去噪性能。考虑到计算量和去噪性能之间的权衡，我们将两个子网的平均接收场大小取为FEB：(41+32)/2=36.5≈37。因此，DudeNet的总体感受野大小为39×39，斑块大小选择为41×41。</p>
<p>​    <strong>2)FEB的设计、分析和有效性：</strong>为了提取准确的特征，我们采用了特征融合的方法来增强DudeNet的表示能力。也就是说，FEB包括第一和第二网络。对于第一种网络，所提出的稀疏机制是一个重要的组成部分，具有以下优点：</p>
<p>​    首先，它可以更好地恢复潜像的细节。其次，它可能导致浅层次的结构，这有利于解决长期依赖问题。第三，浅DudeNet具有较低的计算复杂度。</p>
<p>具体实现见第三节C部分。具体而言，该机制用具有较大膨胀因子的膨胀卷积来模拟大能量点，而用具有小膨胀因子的卷积来表示小能量点以实现稀疏性。然而，选择大的能源点是至关重要的。我们分别从稀疏性特征和网络设计两个方面解释了原因。</p>
<p>​    对于稀疏性，我们知道大的能量点是不规则分布的[47]。在此基础上，提出了寻找大能源点的具体要求。</p>
<p>![img](Users/tianjirong/Library/Group Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image016.png)</p>
<p>​    大能量点在CNN中不是连续的、等距的，这有利于提高去噪性能。如果CNN中的大能量点是连续的，这将导致信息丢失。具体地说，CNN的记忆能力是有限的[48]。CNN的后一层由于不能完全理解前一层的信息，需要学习更大范围的新内容。证明了“连续高能点CB2、CB3网络”的性能比表I所示的“具有稀疏机制的第一网络CB2和CB3(FS)”的性能要差。具体地说，“连续高能点网络CB2、CB3”是CB2、CB3和第一个具有2-5层高能点(膨胀卷积)的网络的组合。此外，还注意到局部地区的网络差异越大，其性能越好[29]。因此，我们在CNN中不会选择等距的大点。这一点通过表I中的“FEBnet1的层2、层5、层8和层11的膨胀因子为2的DudeNet”和“DudeNet”进行了验证。</p>
<p>​    <strong>3）大能量点不多，能保证去噪效率：</strong>举个例子，Elep在处理噪声图像时比FS消耗更多的运行时间，如表II所示。</p>
<p>![img](Users/tianjirong/Library/Group Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image017.png)</p>
<p>​    对于网络结构来说，大能量点是连续的、等距离的、多个的，这会导致效率低、去噪性能差。举个例子，我们假设第一个网络中的每一层都使用膨胀卷积。这需要在第一个网络的每一层进行填充操作，效率较低，如表II所示的“Elep”和“FS”。此外，当感受野的大小大于输入图像的块大小时，特征映射需要零填充，这会降低去噪性能。从表I中比较ELEP和FS的性能可以看出这一点，因此，在图像去噪中放弃了这一思想。此外，稀疏机制在效率和性能上具有竞争力。具体地说，FS的感受场大小为43×43，与核大小为3×3的21层相比，其去噪效果较好，但只有18层，降低了网络深度，提高了去噪效率。</p>
<p>在去噪性能方面，我们通过对表I中的“DudeNet”和“RB、EB、CB和FEB的组合(没有稀疏机制)”和“没有CB2和EB2的DudeNet”的性能进行比较，证明了稀疏机制的有效性。综上所述，FEB的FEBnet1中提出的稀疏机制是有效的。此外，FEBnet2对FEBnet1进行了合并以提高去噪性能，这将在EB中详细说明。</p>
<p>​    <strong>4）EB的设计、分析和有效性：</strong>值得注意的是，不同的网络可以从多个角度提供互补的信息[48]。而且CNN的地方架构差异更大，效果更好[29]。基于此，我们提出了一种增强学习能力的EB。具体地说，EB包括EB1和EB2两个部分。EB1集合了两个子网络，在深度相同的情况下提高了网络的表达能力。可以看出，“RB、EB1、CB和FEB无稀疏机制和BN的组合”比“FWS”和“第二个有CB2和CB3的网络”获得了更高的峰值信噪比(PSNR)。“有CB2的DudeNet和没有EB2的DudeNet”优于“FS”和“有CB2的第二个网络和CB3”。证明了FEB和EB1相结合对图像去噪是非常有效的。具体地说，两个子网络只使用一种稀疏机制来扩大FEB的差异，这在表I中是有效的，例如“具有两个稀疏机制的DudeNet”和“DudeNet”。证明了具有稀疏机制的双网络可以提取不同的特征，提高了去噪器的泛化能力。</p>
<p>​    EB2融合了获得的局部特征和原始图像信息，也可以为第一阶段和以后的网络提供补充信息。通过比较“无稀疏机制的Rb、EB1、Cb和FEB的组合”和“无稀疏机制的Rb、Eb、Cb和FEB的组合”、“DudeNet”和“DudeNet有Cb2和无EB2的DudeNet”来验证这一点。同时，BN并入FEB和EB对DudeNet有积极的影响，这反映在表I中。其原因有以下两点。首先，第一个网络中的膨胀卷积会导致所获得的特征分布不同。其次，从两个不同的网络中获取的特征不同，导致融合后的特征分布不同。这些都对图像去噪有很好的效果。因此，我们选择BN进入第一个网络，并在FEB份选择EB1来分别解决这些问题。此外，值得注意的是，EB1和EB2融合了局部特征和全局特征来增强表达能力，非常适合于未知的受污染图像，如真实世界中的噪声图像和盲去噪。</p>
<p>​    <strong>5)CB的设计、分析和有效性：</strong>为了提高效率，CB通过1×1卷积的方式对冗余特征信息进行打折。由于CB1被嵌入到FEB的第二个网络中，CB3可以将噪声特征转换为噪声映射(也称为噪声图像)。因此，我们只证明了CB2算法对图像去噪的有效性。也就是说，“有CB2的DudeNet和没有EB2的DudeNet”获得了比表I所示的“没有CB2和EB2的DudeNet”更高的PSRN。此外，如表I-III所示，有CB的DudeNet(也称为DudeNet)在性能、运行时间和计算成本方面与“每层内核大小为3×3的DudeNet”具有很强的竞争力。具体地说，为了使去噪结果更具说服力，DudeNet深度参考了DnCNN。然而，由于EB2和CB3的存在，DudeNet的深度在DnCNN之上有一层。另外，我们的网络比DnCNN更广。考虑到这些因素，我们选择18层的“两个DnCNN”作为比较方法，从峰值信噪比、运行时间和复杂度三个方面对去噪性能进行测试，其中“两个DnCNN”是由两个相同的DnCNN串联而成的。</p>
<p>​    在去噪效果上，‘DudeNet’优于表I所示的‘DnCNN’和‘Two DnCNN’。从运行时可以看出，对于有噪声的图像，‘DudeNet’接近于‘Two DnCNN’(即256×256、512×512和1024×1024)。从复杂度来看，‘DudeNet’比‘Two DnCNN’具有更少的参数和Gflops。就去噪网络的复杂度而言，“DudeNet”优于“RED30”和“每层核大小为3×3的DudeNet”。这表明该器件结构浅，滤波器尺寸小，具有较小的计算量和存储量。因此，我们的DudeNet对图像去噪是有效和高效的。</p>
<p><strong>E.  与最先进的去噪方法的比较：</strong></p>
<p>​    本文对灰度和彩色合成噪声图像、盲去噪图像和真实噪声图像四个应用进行了对比实验，并对每幅图像的运行时间进行了比较。对于这些实验，我们选择了最先进的方法，包括BM3D[5]，WNNM[4]，期望补丁对数似然(EPLL)[44]，多层感知器(MLP)[52]，CSF[8]，TNRD[9]，DnCNN[10]，DnCNN用于盲去噪(DnCNN-B)[10]，IRCNN[16]，FFDNet[15]，目标图像去噪(TID)[53。具体地说，我们使用PSNR[55，56]和运行时间作为比较去噪方法的性能指标：PSNR=10×log10((Max)2)，其中Max和MSE MSE分别是给定的干净图像和预测的干净图像之间的最大像素值和均方误差。</p>
<p>![img](Users/tianjirong/Library/Group Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image018.png)</p>
<p>![img](Users/tianjirong/Library/Group Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image019.png)</p>
<p>​    灰度和彩色合成噪声图像：表IV列出了基准数据集BSD68上的灰度合成噪声图像的平均PSNR。可以看出，DudeNet的性能优于几种最先进的去噪器，即DnCNN和FFDNet。此外，带盲去噪的DudeNet(DudeNet-B)也获得了较好的性能。例如，当σ=50时，DudeNet-B比DNCNN有0.02dB的改善。图3显示了来自BSD68上的BM3D、IRCNN、FFDNet、DudeNet和DudeNet-B的可视图像。表V显示了DudeNet对每一类灰度合成噪声图像的良好去噪性能，其中对于不同的噪声级别(即15、25、50)其去噪效果最佳。图4显示了最终图像。可以看出，DudeNet产生的图像比IRCNN清晰得多。从表VI看，在不同的噪声水平(即15、25、35、50、75、[0，55])下，DudeNet和DudeNet-B与CBSD68和Kodak24的其他常用彩色合成噪声图像方法相比具有很强的竞争力。</p>
<p>![img](Users/tianjirong/Library/Group Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image020.png)</p>
<p>![img](Users/tianjirong/Library/Group Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image021.png)</p>
<p>![img](Users/tianjirong/Library/Group Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image022.png)</p>
<p><strong>2)盲去噪：</strong>DudeNet–盲去噪模型。B从0训练到55 3)真实噪声图像：表VII显示了真实噪声图像的去噪性能。</p>
<p>​    DudeNet取得了很好的效果，比DnCNN提高了1.86dB。综上所述，我们的去噪模型适用于复杂的噪声任务，如彩色合成噪声图像、盲降噪和真实噪声图像。如表IV-VI所示，我们可以看到DudeNet-B在灰度和彩色图像去噪方面与FFDNet和IRCNN相比具有很强的竞争力。这证明了我们的模型对盲去噪具有很好的鲁棒性。</p>
<p>![img](Users/tianjirong/Library/Group Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image023.png)</p>
<p>​    表八显示了9种方法在每个不同大小的图像上的运行时间，其中DudeNet比最先进的去噪器(即RED30和MemMet)更具竞争力。表IV-VIII说明了不同方法的去噪性能(即PSNR和运行时间)，其中红线和蓝线分别表示图像去噪的最佳和次佳结果。根据前面第四节D节的分析和第四节E节的实验验证，我们可以将本文的优点提炼如下：</p>
<p>首先，具有稀疏机制的双网络可以提取不同的特征，以增强去噪器处理复杂任务(如真实噪声图像和盲噪声)的广义能力。</p>
<p>其次，将全局特征和局部特征相结合，可以获得显著的特征来恢复细微的细节，从而可以合并双网络来解决复杂的任务。</p>
<p>最后，采用较小的滤波器尺寸来降低去噪器的复杂度。</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>​    本文提出了一种新的DudeNet图像去噪方法。DudeNet使用双重网络来提取不同的特征，以增强学习特征的表示能力以进行去噪。DudeNet的稀疏机制可以很好地在去噪性能和处理速度之间进行权衡，通过提取全局和局部特征来融合它们，获得显著的特征，从而恢复复杂噪声图像的精细细节。我们还提出使用压缩块来减少冗余信息，从而降低计算成本和内存消耗。大量实验表明，DudeNet具有较高的视觉质量和计算效率。在未来，我们打算扩展DudeNet来处理多个低级视觉任务，包括图像超分辨率和去模糊。</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/%E8%AE%BA%E6%96%87/" rel="tag"># 论文</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/07/09/%E5%9F%BA%E4%BA%8E%E6%B5%8B%E9%87%8F%E6%9D%A1%E4%BB%B6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8E%8B%E7%BC%A9%E6%84%9F%E7%9F%A5/" rel="next" title="基于测量条件生成模型的压缩感知">
                <i class="fa fa-chevron-left"></i> 基于测量条件生成模型的压缩感知
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/08/04/%E5%9F%BA%E4%BA%8ESpringBoot+Mybatis+Thymeleaf%E7%9A%84%E5%91%98%E5%B7%A5%E4%BF%A1%E6%81%AF%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/" rel="prev" title="基于SpringBoot+Mybatis+Thymeleaf的员工信息管理系统">
                基于SpringBoot+Mybatis+Thymeleaf的员工信息管理系统 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">田济荣</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%7C%7C%20archive">
              
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/jirong0214" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:geekouc@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://i.loli.net/2020/07/09/PqjnfpmXblhDYOJ.jpg" target="_blank" title="Wechat">
                      
                        <i class="fa fa-fw fa-wechat"></i>Wechat</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#用于图像去噪的双CNN神经网络的设计与训练"><span class="nav-number">1.</span> <span class="nav-text">用于图像去噪的双CNN神经网络的设计与训练</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#摘要"><span class="nav-number">1.1.</span> <span class="nav-text">摘要</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#引言"><span class="nav-number">1.2.</span> <span class="nav-text">引言</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-相关工作："><span class="nav-number">1.3.</span> <span class="nav-text">2 相关工作：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-所提方法"><span class="nav-number">1.4.</span> <span class="nav-text">3 所提方法:</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-实验："><span class="nav-number">1.5.</span> <span class="nav-text">4 实验：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#结论"><span class="nav-number">2.</span> <span class="nav-text">结论</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">田济荣</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a></div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
